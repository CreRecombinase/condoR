% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/condoR.R
\name{read_big_data}
\alias{read_big_data}
\title{Read a really big dataframe}
\usage{
read_big_data(csvfile, key_colname = "Bird", value_colname = "Found",
  chunksize = 100, delim = " ")
}
\arguments{
\item{csvfile}{the name of the .csv file (it can also be compressed, so something like file.csv.gz will work too)}

\item{key_colname}{This is the name for the new "key" column that will be generated, it refers to the non-capitalized columns in the csv}

\item{value_colname}{This is the column for the non-zero values (they're mostly '1', but occasionally X).  It's left to the user to figure out how to deal with these}

\item{chunksize}{The number of rows to read at a time. The default is really small. If you make it bigger it will go faster, but if you make it too big, your computer will die}

\item{delim}{default is " " for space delimited.  If you use tabs use "\t", for commas, use ","}
}
\description{
Read a really big dataframe
}

